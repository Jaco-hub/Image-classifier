# imports of packages
%matplotlib inline
%config InlineBackend.figure_format = 'retina'

import matplotlib.pyplot as plt
import numpy as np
import json
import torch
from torch import nn
from torch import optim
import torch.nn.functional as F
from torch.autograd import Variable
import torchvision
from torchvision import datasets, transforms, models
from collections import OrderedDict
import time
from PIL import Image
import seaborn as sb

data_dir = 'flowers'
train_dir = data_dir + '/train'
valid_dir = data_dir + '/valid'
test_dir = data_dir + '/test'

# TODO: Define your transforms for the training, validation, and testing sets
# transforms =
train_transforms = transforms.Compose([transforms.RandomRotation(30),
                                       transforms.RandomResizedCrop(224),
                                       transforms.RandomHorizontalFlip(),
                                       transforms.ToTensor(),
                                       transforms.Normalize([0.485, 0.456, 0.406], 
                                                            [0.229, 0.224, 0.225])])

valid_test_transforms = transforms.Compose([transforms.Resize(2556),
                                       transforms.CenterCrop(224),
                                       transforms.ToTensor(),
                                       transforms.Normalize([0.485, 0.456, 0.406], 
                                                            [0.229, 0.224, 0.225])])

# TODO: Load the datasets with ImageFolder
# image_datasets = 
train_data = datasets.ImageFolder(train_dir, transform=train_transforms)
valid_data = datasets.ImageFolder(valid_dir, transform=valid_test_transforms)
test_data = datasets.ImageFolder(test_dir, transform=valid_test_transforms)


# TODO: Using the image datasets and the trainforms, define the dataloaders
# dataloaders =
trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)
validloader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=False)
testloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)

with open('cat_to_name.json', 'r') as f:
    cat_to_name = json.load(f)
    
# TODO: Build and train your network
# load a pre-trained netwerk, VGG 16
model = models.vgg16(pretrained=True)
model


# VGG16 has classifier with 3 layers, need to replace it completely. In_features = 25088
# Freeze parameters so we don't backprop through them
for param in model.parameters():
    param.requires_grad = False

# Define new classifier
classifier = nn.Sequential(OrderedDict([
                          ('fc1', nn.Linear(25088, 4096, bias=True)),
                          ('relu1', nn.ReLU()),
                          ('dropout1', nn.Dropout(p=0.3)),
                          ('fc2', nn.Linear(4096, 1024, bias=True)),
                          ('relu2', nn.ReLU()),
                          ('dropout2', nn.Dropout(p=0.3)),
                          ('fc3', nn.Linear(1024, 102)),
                          ('output', nn.LogSoftmax(dim=1))
                          ]))
    
model.classifier = classifier

# install cuda to calc with GPU
device = torch.device ("cuda" if torch.cuda.is_available() else "cpu")

# Loss with the Negative Log LikeLihood
criterion = nn.NLLLoss()

# Adam is the chosen Optimizer
optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)

# Put the model into the GPU
model.to(device)

# Define the training parameters
epochs = 2
steps = 0
train_loss = 0
print_every = 50

# Let's start training!
for ii in range(epochs):
    for images, labels in trainloader:
        steps += 1
    
        # Move image and label tensors to the GPU
        images, labels = images.to(device), labels.to(device)    
    
        #Zeroing the gradients
        optimizer.zero_grad()

        #Forward pass
        output = model.forward(images)
        loss = criterion(output, labels)
    
        # Backward propagation
        loss.backward()
        optimizer.step()
        
        train_loss += loss.item()
        
        #validation
    else:
        valid_loss = 0
        accuracy = 0
        #total = 0
        #correct = 0
        # Make sure network is in eval mode (no drop out) for inference
        model.eval()

        # Turn off gradients for validation, saves memory and computations
        with torch.no_grad():
            for images, labels in validloader:
                #move the data to the gpu
                images, labels = images.to(device), labels.to(device)
                
                # Forward pass with the validation data
                output = model.forward(images)
                valid_loss += criterion(output, labels).item()
                
                # accuracy
                ps = torch.exp(output)
                top_prob, top_class = ps.topk(1, dim=1)
                equality = top_class == labels.view(*top_class.shape)
                accuracy += equality.type(torch.FloatTensor).mean()
        
        print("Epoch: {}/{}.. ".format(ii+1, epochs),
              "Training Loss: {:.3f}.. ".format(train_loss/print_every),
              "Valid Loss: {:.3f}.. ".format(valid_loss/len(validloader)),
              "Valid Accuracy: {:.3f}".format(accuracy/len(validloader)))
            
            
        # Make sure training is back on to allow drop out
        model.train()
